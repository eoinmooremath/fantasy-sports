{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7Nr4rP7UMhdyWt3H0Hn/Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinmooremath/fantasy-sports/blob/main/Fantasy_Football.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DraftKings Football Bet Optimizer**\n",
        "\n",
        "*The code in this notebook can be used to create draft teams with optimal expected value in Draftkings Football Classic Mode.*\n",
        "\n",
        "DraftKings is an online gambling websites where players makes bets on sports games. There are a variety of types of betting one can do, but the main one we will focus on is drafting football in classic mode.\n",
        "\n",
        "To play a DraftKings football classic contest, you first select an eligable roster of available football players who are playing in real life games on a given night. This will be your team for the contest. Based on game actions those players perform, that player will get *fantasy points*. For example, if a player passes a touchdown, that player will get 4 points. If a player throws an interception, they will lose one point. If a player has a rushing touchdown, they will get 6 points. DraftKings tallys each player's point total during the game. Add up all the points of all your team's players to get your score. You compete in a pool of other teams in the contest. Prizes are awarded based on how well many points you got versus your competitors. In the type I like to play -- *50-50* -- you bet, say, 10 dollars, and the top 50% of players will get 1.8x return on their money, in this case winning 18 dollars.\n",
        "\n",
        "The skill of DraftKings lies in your ability to draft a team. You are allotted 50,000 dollars in salary to buy the salaries of your players. Different players have different salaries. Better players have higher salaries. The team you make is independent of the teams other players make, so you can be up against teams with overlapping players. All that is required is that your total salary not exceed 50,000 dollars.\n",
        "\n",
        "Now, this would be a very good opportunity to do deep learning and predict players point scores on a given night based upon factors such as their opposing team's lineup, weather, etc. For this first pass at the project, we are going to take a simpler approach, but one that will allow us to investigate python frameworks for parallel computing and speeding up code with just in time compilation.\n",
        "\n",
        "DraftKings is kind enough to provide us a metric for each player called *fantasy points per game* (fppg). This is the average of fantasy points that player has scored per game during this season. We will use that as a reasonable expectation for how a player will do. Then, why not do the obvious thing -- why not just add up all the players of each position with the highest fppg?  The reason is, if you do that, you will invariably exceed 50,000 dollars salary cap.\n",
        "\n",
        "\n",
        "What we would like to do, then, is pack the 50,000 dollars with the highest fppg expected value (EV) as we can.  Maybe the highest team EV comes from picking almost all of the highest EV players, and one or two low-EV players. Or maybe it comes from picking players who all have modestly high EV. It is hard for us to guess, so instead we will have a computer comb through vast numbers of possibile team combinations, compute each expected fppg, and return the best choice.\n",
        "\n"
      ],
      "metadata": {
        "id": "c7NJwcSA7z8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the necessary libraries.  \n",
        "Pandas is for handling DraftKings' .csv files of player data. Numba is for creating just-in-time code. Dask is for parallelizing the code."
      ],
      "metadata": {
        "id": "Z1aAXOR1JLVr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS_7CIhB52Sg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from numba import njit, prange\n",
        "import dask\n",
        "import itertools\n",
        "from dask import delayed\n",
        "import dask.config\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and process the data.\n",
        "Go to the classic NFL contest that you are interested in creating a team for. Click \\\"Export to CSV \\\" to get the team data. I recommend saving it with the link to the draft in mind. So for example, if the draft is at https://www.draftkings.com/draft/contest/167663950, I will name my file, Football_classic_167663950.csv.\n",
        "\n",
        "Next, we will convert the .csv file into a Pandas database. We will only keep the columns we care about -- \\'Name\\', \\'Position\\', \\'Salary\\', and \\'AvgPointsPerGame\\' which we will rename \\'Fppg\\'. We will have one database `db_all` to hold all our players. We will have one database for each team position as well.\n",
        "\n",
        "*About team formation --*\n",
        "On DraftKings your team consists of exactly nine \\\"players\\\":  \n",
        "\n",
        "1 quarterback; 2 runningbacks; 3 wide receivers; 1 tight end; 1 flex spot -- which is a player from among runningbacks, wide receivers, and tightends; and one defense / special teams slot. (DraftKings doesn't let you individually draft defensive / special teams players. Instead, their collective *team* scores are aggregated as \\\"DST\\\" position. So a DST *player* is actually a team.)   \n"
      ],
      "metadata": {
        "id": "PQxDKZjJKD96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/eoinmooremath/fantasy-sports/b0e5e66762b9e8f55a4ece0f755e7ef64cc793de/Football_classic_167663950.csv'\n",
        "db_all = pd.read_csv(url)\n",
        "db_all.rename(columns={'AvgPointsPerGame':'Fppg'}, inplace=True)\n",
        "db_all = db_all.loc[:,['Name','Position','Salary','Fppg']]\n",
        "db_all['Value']=db_all['Fppg']/db_all['Salary']*10000\n",
        "# \"Value\" is the same as \"expected value.\" The 10000 doesn't mean anything. I just like to multiply by 10000 to make the numbers easier to read.\n",
        "\n",
        "db_d = db_all[db_all['Position']=='DST']\n",
        "db_f = db_all[(db_all['Position']=='RB') | (db_all['Position']=='WR') | (db_all['Position']=='TE') ]\n",
        "db_q = db_all[db_all['Position']=='QB']\n",
        "db_r = db_all[db_all['Position']=='RB']\n",
        "db_t = db_all[db_all['Position']=='TE']\n",
        "db_w = db_all[db_all['Position']=='WR']"
      ],
      "metadata": {
        "id": "kvmE-tOfKkyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the teams\n",
        "\n",
        "Examining the data, we see there are 24 DST players, 499 flex players, 79 quarterbacks, 134 running backs, 138 tight ends, and 277 wide receivers.  That means there are `24*79*134*(134-1)*138*277*(277-1)*(277-2)*(499-6)= 48332840921317814400` possible teams. That's over 48 quintillion teams!  We don't even have time to check *one* quintillion teams for Sunday's contest, so we need to be judicious in the teams we compute the fppg for. If we have fewer players to check, there are fewer teams to check.\n",
        "\n",
        "The way we will trim our player selection is with the `get_players_at_rate()` function below. We want to select only those players who have a good expected value compared to other players. `get_players_at_rate(z,players)` returns those players in the `players` database who have a z-score at least `z`. That means they are `z`-standard deviations above the mean. For example, `get_players_at_rate(2,db_q)` will return those quarterbacks who are at least two standard deviations above the mean of quarterbacks.  \n",
        "\n",
        "Also, thinking about our code, we want it to be as lightweight as possible. We don't need to return the overhead of a pandas database, when we are planning on accessing this information billions of times. Instead, we will store only the necessary information in a numpy array. Each row will correspond to a player. The first column will be their index (to refer to them later in the `db_all` database once we get a team), and the last two will be their pppg rate and their salary.\n",
        "\n",
        "After we create a roster of players to choose from, we would like to know how many possible teams we have to search through. This is what the `get_size` function is for.  For example, `get_size(db_d,db_f,db_q,db_r,db_t,db_w) = 48332840921317814400` If it is too large, we can adjust the teams with different rates, and try again.\n"
      ],
      "metadata": {
        "id": "fkAQ3SrGbRxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_players_at_value(z,players):\n",
        "    # input: players == pandas array of players of a certain position, corresponding to a position.  z == desired z-score\n",
        "    # special case, let z<0 to return players who have a positive rate (not necessarily above mean)\n",
        "    # output: numpy array of those players with z-score at least z, in a numpy array.\n",
        "    # the first column is the index. the second column is  Pppg. The third is Salary\n",
        "    if z<0:\n",
        "        players=players[players['Value']>0]\n",
        "    if z>=0:\n",
        "        players=players[players['Value']>= (players['Value'].mean()+z*players['Value'].std())]\n",
        "    players = players.sort_values(by='Value', ascending=False)\n",
        "    players = players.loc[:,['Fppg','Salary']]\n",
        "    players = players.reset_index()\n",
        "    players = players.to_numpy()\n",
        "\n",
        "    return players\n",
        "\n",
        "def get_size(d,f,q,r,t,w):\n",
        "    num_teams = len(q)* ( len(r)* (len(r)-1) ) * ( len(w) * (len(w)-1) * (len(w)-2) ) * len(t) * len(f) * len(d)\n",
        "    return num_teams\n"
      ],
      "metadata": {
        "id": "fIbbKbjD69YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute the best team\n",
        "\n",
        "I will now give you the code which you can call to create the best team. Later I will talk about a possible work flow.\n",
        "\n",
        "Essentially, this code is one massive for-loop. We use nested for-loops to create all possible teams among our selected players. We calculate the team's expected value by adding up the EVs of all of its players. We keep only the team with the highest EV that also has a total price less than \\$50,000.\n",
        "\n",
        "I first wrote my code naively without any optimization. It took a long time to run. I could trim the team sizes or expect long wait times. I researched a bit and found that *just in time* compilation with numba could significantly speed up my program. Numba takes the easy-to-type but slow-to-run python code and translates it into optimized machine code at runtime. I edited my program so that it would be compatible with Numba. The results were dramatic. In experiments, I saw a *speed up of around* **80x**.\n",
        "\n",
        "After further consideration, I realized that the computations within the for-loop are independent of each other, making them well-suited for parallelization, which can further speed up the code. Dask is a parallel computing framework that allows Python code to be executed across multiple cores of your CPU or even distributed across a cluster. I generate batches of teams. Dask distributes those batches to available CPU cores, processing them concurrently. Once the computations are complete, the results are collected, and the best team among all is kept. After implementing Dash, this time *I saw another speed up around* **1.3x**  from just Numba alone. Dash with Numba provided a *total speed up of around* **100x** compared to the plain vanilla version.  \n",
        "\n",
        "Here are all three versions, ordered from fastest to slowest."
      ],
      "metadata": {
        "id": "AOkdvqv1lmNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dask and Numba version\n"
      ],
      "metadata": {
        "id": "WtllFaTjsqgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def inner_loop_dask(players_d, players_f, players_q, players_r, players_t, players_w, w1, w2, w3):\n",
        "    # How you break this up seems arbitrary, and open to experimentation. Batches will differ according to\n",
        "    # their wide receivers. So take those as constants. Inside this inner loop, we will loop over all possible\n",
        "    # remaining players. You could choose to break the loop up differently, and perhaps achieve different speed-ups.\n",
        "    d_len = len(players_d)\n",
        "    f_len = len(players_f)\n",
        "    q_len = len(players_q)\n",
        "    r_len = len(players_r)\n",
        "    t_len = len(players_t)\n",
        "    best_EV = 0\n",
        "\n",
        "    def test_no_repeats(arr):  # this is to make sure that we don't accidently pick the same player twice\n",
        "        for x in range(len(arr)):\n",
        "            for y in range(x+1,len(arr)):\n",
        "                if arr[x]==arr[y]:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    for d in range(d_len):  # the nested for-loops get the team.\n",
        "        for f in range(f_len):\n",
        "            for q in range(q_len):\n",
        "                for r1 in range(r_len):\n",
        "                    for r2 in range(r1+1, r_len):\n",
        "                        for t in range(t_len):  # if the team is under $50,000 and is better than the previous best team, keep it, and its EV.\n",
        "                            points_EV = (players_d[d, 1] + players_f[f, 1] +\n",
        "                                            players_q[q, 1] + players_r[r1, 1] +\n",
        "                                            players_r[r2, 1] + players_t[t, 1] +\n",
        "                                            players_w[w1, 1] + players_w[w2, 1] +\n",
        "                                            players_w[w3, 1])\n",
        "                            team_price = (players_d[d, 2] + players_f[f, 2] + players_q[q, 2]\n",
        "                                           +players_r[r1, 2] + players_r[r2, 2]\n",
        "                                            + players_t[t, 2] +\n",
        "                                            players_w[w1, 2] + players_w[w2, 2] +players_w[w3,2])\n",
        "                            test_set = np.array([players_r[r1, 0], players_r[r2, 0],\n",
        "                                                players_w[w1, 0], players_w[w2, 0],\n",
        "                                                players_w[w3, 0], players_f[f,0]])\n",
        "                            no_repeats = test_no_repeats(test_set)\n",
        "\n",
        "                            if ((points_EV > best_EV) and (team_price < 50000) and no_repeats):\n",
        "                                best_EV = points_EV\n",
        "\n",
        "                                best_team = np.array([\n",
        "                                     players_d[d, 0], players_f[f, 0], players_q[q, 0],\n",
        "                                     players_r[r1, 0], players_r[r2, 0], players_t[t, 0],\n",
        "                                     players_w[w1, 0], players_w[w2, 0], players_w[w3, 0]\n",
        "                                ])\n",
        "\n",
        "    return best_team, best_EV\n",
        "\n",
        "@dask.delayed\n",
        "def make_team_dask(players_d, players_f, players_q, players_r, players_t, players_w):\n",
        "    w = list(itertools.combinations(range(len(players_w)), 3))\n",
        "    # itertools.combinations is an efficient and fast way to generate all possible\n",
        "    # 3-player permutations of wide receivers, which is what we need.  Loop over them.\n",
        "    best_EV = 0\n",
        "    for idx in range(len(w)):\n",
        "        w1, w2, w3 = w[idx]\n",
        "        team, EV = inner_loop_dask(players_d, players_f, players_q, players_r, players_t, players_w, w1, w2, w3)\n",
        "        if EV >= best_EV:\n",
        "            best_EV = EV\n",
        "            best_team = team\n",
        "    return best_team\n"
      ],
      "metadata": {
        "id": "O78JCRlU7L_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numba version"
      ],
      "metadata": {
        "id": "LXlxwwRls5tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def make_team_njit(players_d, players_f, players_q, players_r, players_t, players_w):\n",
        "    d_len = len(players_d)\n",
        "    f_len = len(players_f)\n",
        "    q_len = len(players_q)\n",
        "    r_len = len(players_r)\n",
        "    t_len = len(players_t)\n",
        "    w_len = len(players_w)\n",
        "    best_EV = 0\n",
        "\n",
        "    def test_no_repeats(arr):\n",
        "        for x in range(len(arr)):\n",
        "            for y in range(x+1,len(arr)):\n",
        "                if arr[x]==arr[y]:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    for d in range(d_len):\n",
        "        for f in range(f_len):\n",
        "            for q in range(q_len):\n",
        "                for r1 in range(r_len):\n",
        "                    for r2 in range(r1+1, r_len):\n",
        "                        for t in range(t_len):\n",
        "                            for w1 in range(w_len):\n",
        "                                for w2 in range(w1+1, w_len):\n",
        "                                    for w3 in range(w2, w_len):\n",
        "                                        points_EV = (players_d[d, 1] + players_f[f, 1] +\n",
        "                                                        players_q[q, 1] + players_r[r1, 1] +\n",
        "                                                        players_r[r2, 1] + players_t[t, 1] +\n",
        "                                                        players_w[w1, 1] + players_w[w2, 1] +\n",
        "                                                        players_w[w3, 1])\n",
        "                                        team_price = (players_d[d, 2] + players_f[f, 2] + players_q[q, 2]\n",
        "                                                      +players_r[r1, 2] + players_r[r2, 2]\n",
        "                                                        + players_t[t, 2] +\n",
        "                                                        players_w[w1, 2] + players_w[w2, 2] +players_w[w3,2])\n",
        "                                        test_set = np.array([players_r[r1, 0], players_r[r2, 0],\n",
        "                                                            players_w[w1, 0], players_w[w2, 0],\n",
        "                                                            players_w[w3, 0], players_f[f,0]])\n",
        "                                        no_repeats = test_no_repeats(test_set)\n",
        "\n",
        "                                        if ((points_EV > best_EV) and (team_price < 50000) and no_repeats):\n",
        "                                            best_EV = points_EV\n",
        "\n",
        "                                            best_team = np.array([\n",
        "                                                players_d[d, 0], players_f[f, 0], players_q[q, 0],\n",
        "                                                players_r[r1, 0], players_r[r2, 0], players_t[t, 0],\n",
        "                                                players_w[w1, 0], players_w[w2, 0], players_w[w3, 0]\n",
        "                                            ])\n",
        "    return best_team\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLDY17687Ngg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vanilla version (no optimization)"
      ],
      "metadata": {
        "id": "bQRIhWi87Or9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_team_vanilla(players_d, players_f, players_q, players_r, players_t, players_w):  #this is the same as the numba version, just without the decorator\n",
        "    d_len = len(players_d)\n",
        "    f_len = len(players_f)\n",
        "    q_len = len(players_q)\n",
        "    r_len = len(players_r)\n",
        "    t_len = len(players_t)\n",
        "    w_len = len(players_w)\n",
        "    best_EV = 0\n",
        "\n",
        "    def test_no_repeats(arr):\n",
        "        for x in range(len(arr)):\n",
        "            for y in range(x+1,len(arr)):\n",
        "                if arr[x]==arr[y]:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    for d in range(d_len):\n",
        "        for f in range(f_len):\n",
        "            for q in range(q_len):\n",
        "                for r1 in range(r_len):\n",
        "                    for r2 in range(r1+1, r_len):\n",
        "                        for t in range(t_len):\n",
        "                            for w1 in range(w_len):\n",
        "                                for w2 in range(w1+1, w_len):\n",
        "                                    for w3 in range(w2, w_len):\n",
        "                                        points_EV = (players_d[d, 1] + players_f[f, 1] +\n",
        "                                                        players_q[q, 1] + players_r[r1, 1] +\n",
        "                                                        players_r[r2, 1] + players_t[t, 1] +\n",
        "                                                        players_w[w1, 1] + players_w[w2, 1] +\n",
        "                                                        players_w[w3, 1])\n",
        "                                        team_price = (players_d[d, 2] + players_f[f, 2] + players_q[q, 2]\n",
        "                                                      +players_r[r1, 2] + players_r[r2, 2]\n",
        "                                                        + players_t[t, 2] +\n",
        "                                                        players_w[w1, 2] + players_w[w2, 2] +players_w[w3,2])\n",
        "                                        test_set = np.array([players_r[r1, 0], players_r[r2, 0],\n",
        "                                                            players_w[w1, 0], players_w[w2, 0],\n",
        "                                                            players_w[w3, 0], players_f[f,0]])\n",
        "                                        no_repeats = test_no_repeats(test_set)\n",
        "\n",
        "                                        if ((points_EV > best_EV) and (team_price < 50000) and no_repeats):\n",
        "                                            best_EV = points_EV\n",
        "\n",
        "                                            best_team = np.array([\n",
        "                                                players_d[d, 0], players_f[f, 0], players_q[q, 0],\n",
        "                                                players_r[r1, 0], players_r[r2, 0], players_t[t, 0],\n",
        "                                                players_w[w1, 0], players_w[w2, 0], players_w[w3, 0]\n",
        "                                            ])\n",
        "    return best_team\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gFz3VDc47ej-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workflow\n",
        "\n",
        "The calculations performed inside the for-loops are relatively simple. Theoretically, the time it takes to run the program should scale linearly with the number of teams compared.  I find this to hold experimentally, as well. This suggests a workflow where we can target the program to run in a desired amount of time.\n",
        "\n",
        "Create a small roster using `get_players_at_rate`. Calculate the number of possible teams it generates using the `get_size` function, storing the result in a variable `num_teams`. Next, measure the time it takes to compute the best team from that roster and call it, say, `t`. Let `t_max` be the amount of time you are willing to spend on the computation.\n",
        "\n",
        "Then, you are looking for a roster size equal to about `num_teams * (t_max / t)`.\n",
        "\n",
        "Play around with the `get_players_at_rate` function to produce rosters until you hit your goal. Note, you might not want to get all positions at the same right. If you do, you might be left with a roster with lots of flex-spots, but few DST choices.\n",
        "\n",
        "This isn't *quite* right, especially for Dask, as the parallelization adds overhead that will disproportionately impact smaller runs. This is why you will see the Numba code runs the fastest below.  \n",
        "\n",
        "Note also that we run the Dask code a little differently than usual."
      ],
      "metadata": {
        "id": "V3BZnqBOtnYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strict_rate = 2.5\n",
        "\n",
        "select_d = get_players_at_value(1,db_d)\n",
        "select_f = get_players_at_value(strict_rate,db_f)\n",
        "select_q = get_players_at_value(2,db_q)\n",
        "select_r = get_players_at_value(strict_rate,db_r)\n",
        "select_t = get_players_at_value(strict_rate,db_t)\n",
        "select_w = get_players_at_value(strict_rate,db_w)\n",
        "\n",
        "num_teams = get_size(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "print(f\"Number of possible teams: {num_teams}\")\n",
        "print()\n",
        "\n",
        "\n",
        "team_dask_ddo = make_team_dask(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "#this makes a 'Dask delayed object' only. Compute the result by running .compute() on it.\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "team_dask=team_dask_ddo.compute()\n",
        "end_time = time.perf_counter()\n",
        "t_dask = end_time-start_time\n",
        "print(f\"Dask execution time: {t_dask} seconds\")\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "team_njit = make_team_njit(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "end_time = time.perf_counter()\n",
        "t_njit = end_time-start_time\n",
        "print(f\"Numba execution time: {t_njit} seconds\")\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "team_van = make_team_vanilla(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "end_time = time.perf_counter()\n",
        "t_van = end_time-start_time\n",
        "print(f\"Unoptomized execution time: {t_van} seconds\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"For Dask, the salary is {db_all.loc[team_dask,:]['Salary'].sum()} and points EV is  {db_all.loc[team_dask,:]['Fppg'].sum()}\")\n",
        "print(db_all.iloc[team_dask,:])\n",
        "print()\n",
        "\n",
        "print(f\"For Numba, the salary is {db_all.loc[team_njit,:]['Salary'].sum()} and points EV is  {db_all.loc[team_njit,:]['Fppg'].sum()}\")\n",
        "print(db_all.iloc[team_njit,:])\n",
        "print()\n",
        "\n",
        "print(f\"For Vanilla, the salary is {db_all.loc[team_van,:]['Salary'].sum()} and points EV is  {db_all.loc[team_van,:]['Fppg'].sum()}\")\n",
        "print(db_all.iloc[team_van,:])\n",
        "print()\n",
        "print(\"It's a good check to see that all give the same result!\")"
      ],
      "metadata": {
        "id": "AYZ09r7K3E-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strict_rate = 2\n",
        "\n",
        "select_d = get_players_at_value(1,db_d)\n",
        "select_f = get_players_at_value(strict_rate,db_f)\n",
        "select_q = get_players_at_value(strict_rate,db_q)\n",
        "select_r = get_players_at_value(strict_rate,db_r)\n",
        "select_t = get_players_at_value(strict_rate,db_t)\n",
        "select_w = get_players_at_value(strict_rate,db_w)\n",
        "num_teams2 = get_size(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "print(f\"Number of possible teams: {num_teams2}\")\n",
        "print(f\"Expect times to take  {num_teams2/num_teams} x longer.\")"
      ],
      "metadata": {
        "id": "kaHlC7M5Oq4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will test slightly larger arrays, especially to see how Dask does when the overhead will be relatively smaller compared to the whole task. We anticipate that running the unoptimized version will take a while, so we will run that in a separate cell."
      ],
      "metadata": {
        "id": "cJSXo-sYPk3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "team_dask_ddo2 = make_team_dask(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "team_dask2=team_dask_ddo2.compute()\n",
        "end_time = time.perf_counter()\n",
        "t_dask2 = end_time-start_time\n",
        "print(f\"Dask execution time: {t_dask2} seconds. That is {t_dask2/t_dask} slower than the previous run. We expected a slowdown factor of {num_teams2/num_teams}.\")\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "team_njit2 = make_team_njit(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "end_time = time.perf_counter()\n",
        "t_njit2 = end_time-start_time\n",
        "print(f\"Numba execution time: {t_njit2} seconds.  That is {t_njit2/t_njit} slower than the previous run. We expected a slowdown factor of {num_teams2/num_teams}.\")\n",
        "print()\n",
        "print(f\"The salary is {db_all.loc[team_dask2,:]['Salary'].sum()} and points EV is  {db_all.loc[team_dask2,:]['Fppg'].sum()}\")\n",
        "print(db_all.iloc[team_dask2,:])\n",
        "print()\n",
        "print('Compare this to the team we got before:')\n",
        "print(f\"The salary is {db_all.loc[team_van,:]['Salary'].sum()} and points EV is  {db_all.loc[team_van,:]['Fppg'].sum()}\")\n",
        "print(db_all.iloc[team_van,:])"
      ],
      "metadata": {
        "id": "8pzYQ_wE_7gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, Dash slowed down less than expected, which means that it sped up *more* than expected! This is for the reasons of overhead explained earlier. We also see that both rosters produce the same team. That's a little dissapointing. Hopefully we will get a better team when we compute over an even larger roster.\n",
        "\n",
        "You can try running the code below to see how the unoptimized version does, however you might run into problems if you are using the free version of Google Colab. Mine timed out after many hours running on Google Colab.\n",
        "\n",
        "However, I did the same experiments on my personal computer, which is a little faster than my Google Colab instance. It took 184.86 seconds to run.  There, (and this also was about the same on larger runs) --  \n",
        "\n",
        " **Dask with Numba was 1.31x faster than just Numba and 104x faster than unoptimized code. Numba was 79.6x faster than unoptimized code.**\n",
        "\n"
      ],
      "metadata": {
        "id": "CPfn3RxER3kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.perf_counter()\n",
        "team_van2 = make_team_vanilla(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "end_time = time.perf_counter()\n",
        "t_van2 = end_time-start_timeprint(f\"Numba execution time: {t_van2} seconds.  That is {t_van2/t_van} slower than the previous run. We expected a slowdown factor of {num_teams2/num_teams}.\")\n",
        "print()\n",
        "print(f\"Dask with Numba was {t_njit2/t_dask2 }x faster than just Numba and {t_van2/t_dask2}x faster than unoptimized code. Numba was {t_van2/t_njit2}x faster than unoptimized code.\")"
      ],
      "metadata": {
        "id": "UId2ENslR2_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will compute an actual, realistic roster, this time with just Dask and Numba."
      ],
      "metadata": {
        "id": "qzi2t-1ETDAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rate = 1\n",
        "\n",
        "select_d = get_players_at_value(-1,db_d)\n",
        "select_f = get_players_at_value(2,db_f)\n",
        "select_q = get_players_at_value(rate,db_q)\n",
        "select_r = get_players_at_value(rate,db_r)\n",
        "select_t = get_players_at_value(rate,db_t)\n",
        "select_w = get_players_at_value(1.5,db_w)\n",
        "num_teams3 = get_size(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "print(f\"Number of possible teams: {num_teams2}\")\n",
        "print(f\"Expect it to take {num_teams3/num_teams2*t_dask2} seconds or {num_teams3/num_teams2*t_dask2/3600} hours.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "whdzUl8B8Oya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team_dask_ddo3 = make_team_dask(select_d,select_f,select_q,select_r,select_t,select_w)\n",
        "start_time = time.perf_counter()\n",
        "team_dask3=team_dask_ddo3.compute()\n",
        "end_time = time.perf_counter()\n",
        "\n",
        "\n",
        "print(f\"That took {end_time-start_time} seconds. We expected it to take {num_teams3/num_teams2*t_dask2} seconds .\")\n",
        "print()\n",
        "print(f\"The salary is {db_all.loc[team_dask3,:]['Salary'].sum()} and points EV is  {db_all.loc[team_dask3,:]['Fppg'].sum()}\")\n",
        "print(db_all.iloc[team_dask3,:])\n",
        "print()\n",
        "print('Compare this to the team we got before:')\n",
        "print(f\"The salary is {db_all.loc[team_van,:]['Salary'].sum()} and points EV is  {db_all.loc[team_van,:]['Fppg'].sum()}\")\n",
        "print(db_all.iloc[team_van,:])"
      ],
      "metadata": {
        "id": "FMI-rYG4WWhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future directions\n",
        "\n",
        "The next logical thing to do would be to have the algortihm run in parallel on GPUs or clusters of GPUs. I looked into doing this, but haven't yet figured out how to do it.\n",
        "\n",
        "More impactfully, I would like to apply deep learning to get more accurate points forecast.  Currently I use a player's average pppg to estimate how many player points they will score in their game. There are certain flaws with this thinking, though. For example, if my quarterback is playing against my defensive team, do I expect them both to have good (or average) games?\n",
        "\n",
        "Using deep learning, we could train a model on historical NFL and college football game data, stripping the data that would identify specific players, and instead focus on how different positions correlate with other positions in generating points. Later, fine-tune the model on today's players, capturing specific player-player interactions.\n",
        "\n",
        "We could also use machine learning to return not just the highest EV team, but also a number of high EV teams which cummulatively have, say, the lowest risk. We would create a portfolio of teams to bet on.\n",
        "\n",
        "With more accurate point forecast, and more robust team creation, we would then compute the best teams using GPU accelerated technology.\n",
        "\n",
        "That's the vision for where I want to take this project. If you have any ideas or want to help, please let me know.\n",
        "\n",
        "This code can easily be adapted to other sports on DraftKings, and I have already done so for golf."
      ],
      "metadata": {
        "id": "P0rmyUS7wFpE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LdC9oDUP1nM6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}